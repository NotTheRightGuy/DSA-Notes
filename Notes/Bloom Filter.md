
A **Bloom filter** is a space-efficient [probabilistic](https://en.wikipedia.org/wiki/Probabilistic "Probabilistic") [data structure](https://en.wikipedia.org/wiki/Data_structure "Data structure"), conceived by [Burton Howard Bloom](https://en.wikipedia.org/w/index.php?title=Burton_Howard_Bloom&action=edit&redlink=1 "Burton Howard Bloom (page does not exist)") in 1970, that is used to test whether an [element](https://en.wikipedia.org/wiki/Element_(mathematics) "Element (mathematics)") is a member of a [set](https://en.wikipedia.org/wiki/Set_(computer_science) "Set (computer science)"). [False positive](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors "Type I and type II errors") matches are possible, but [false negatives](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors "Type I and type II errors") are not – in other words, a query returns either "possibly in set" or "definitely not in set". Elements can be added to the set, but not removed (though this can be addressed with the [counting Bloom filter](https://en.wikipedia.org/wiki/Bloom_filter#Counting_Bloom_filters) variant); the more items added, the larger the probability of false positives.

Bloom proposed the technique for applications where the amount of source data would require an impractically large amount of memory if "conventional" error-free [hashing](https://en.wikipedia.org/wiki/Hash_function "Hash function") techniques were applied. He gave the example of a [hyphenation algorithm](https://en.wikipedia.org/wiki/Hyphenation_algorithm "Hyphenation algorithm") for a dictionary of 500,000 words, out of which 90% follow simple hyphenation rules, but the remaining 10% require expensive disk accesses to retrieve specific hyphenation patterns. With sufficient [core memory](https://en.wikipedia.org/wiki/Core_memory "Core memory"), an error-free hash could be used to eliminate all unnecessary disk accesses; on the other hand, with limited core memory, Bloom's technique uses a smaller hash area but still eliminates most unnecessary accesses. For example, a hash area only 15% of the size needed by an ideal error-free hash still eliminates 85% of the disk accesses.


